<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <!-- <meta name="description" content="DESCRIPTION META TAG"> -->
    <meta property="og:title"
        content="Skip-GANomaly++: Skip Connections and Residual Blocks for Anomaly Detection" />
    <!-- <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" /> -->
    <meta property="og:url" content="https://crinex.github.io/pages/skipganpp/" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <!-- <meta property="og:image" content="static/images/banner.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" /> -->


    <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
    <!-- <meta name="twitter:card" content="summary_large_image"> -->
    <!-- Keywords for your paper to be indexed by-->
    <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE"> -->
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->


    <title>Skip-GANomlay++</title>
    <!-- <link rel="icon" type="image/x-icon" href="static/images/koala.png">-->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/index.js"></script>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.1.1/gradio.js"></script>
</head>

<body>


    <section class="hero banner">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title"></i>Skip-GANomaly++<br />
                            :Skip Connections and Residual Blocks for Anomaly Detection</h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <span class="author-block">
                                <a href="https://aunal.org/people/jypark" target="_blank">â€ June-Young Park</a><sup style="color:#aa0404;">1 </sup>,</span>
                            <span class="author-block">
                                <a href="https://www.dkuh.co.kr/html_2016/03/01_02.php?idx=456150&url=%2Fhtml_2016%2F03%2F01.php&drword=%EC%8B%A0%ED%98%9C%EB%A6%BC" target="_blank">Jae-Ryung Hong</a><sup style="color:#439b08;">2</sup>,</span>
                            <span class="author-block">
                                <a href="https://www.dkuh.co.kr/html_2016/03/01_02.php?idx=456150&url=%2Fhtml_2016%2F03%2F01.php&drword=%EC%8B%A0%ED%98%9C%EB%A6%BC" target="_blank">Min-Hye Kim</a><sup style="color:#ecaa2e;">3</sup>,</span>
                            <span class="author-block">
                                <a href="https://aunal.org/people/tjkim" target="_blank">Tae-Joon Kim</a><sup style="color:#ecaa2e;">3</sup></span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup style="color:#aa0404;">1</sup>Graduate School of Medicine Ajou University,</span>
                            <span class="author-block"><sup style="color:#439b08;">2</sup>Ewha Womans University,</span>
                            <span class="author-block"><sup style="color:#ecaa2e;">3</sup>Ajou University School of Medicine</span>
                        </div>
                        â€ {crinexk@gmail.com}
                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="https://ieeexplore.ieee.org/document/10320072" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>AAAI 2024</span>
                    
                                    </a>
                                </span>


                                <!-- <span class="link-block">
                                    <a href="https://huggingface.co/docs/diffusers/main/en/api/pipelines/pixart" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">ðŸ§¨</span>
                                        <span>Diffusers</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://huggingface.co/spaces/PixArt-alpha/PixArt-alpha" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">ðŸ¤—</span>
                                        <span>HF Demo</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://openxlab.org.cn/apps/detail/PixArt-alpha/PixArt-alpha" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">X</span>
                                        <span>OpenXLab Demo</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2310.00426" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://discord.gg/hWT7caau" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-discord"></i>
                                        </span>
                                        <span>Discord</span>
                                    </a>
                                </span> -->
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Image carousel -->
    <!-- End image carousel -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Anomaly detection is a critical task across various domains. 
                            Fundamentally, anomaly detection models offer methods to identify unusual patterns that do not align with expected be-haviors. 
                            Notably, in the medical field, detecting anomalies in medical imagery or biometrics can facilitate early diagno-sis of diseases. 
                            Consequently, we propose the Skip-GANomaly++ model, an enhanced and more efficient ver-sion of the conventional anomaly detection models. 
                            The proposed model's performance was evaluated through com-parative experiments. 
                            Experimental results demonstrated superior performance across most classes compared to the previous models.
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->
    
    <!-- Start demo page -->
    <!-- <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-centered has-text-centered">
                <h2 class="title is-3">Online Demo</h2>
                <gradio-app src="https://pixart-alpha-pixart-alpha.hf.space" style="display: flex; justify-content: center;"></gradio-app>
            </div>
        </div>
    </section> -->
    <!-- End demo page -->


    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">Proposed Model</h2>
                <p>
                    To train and evaluate our proposed OSA-Net model,
                    we used facial images of patients who underwent PSG tests
                    at the Neurology Department of Cheonan Dankook
                    University Hospital from 2012 to 2022. 
                    The data were obtained from adults aged 19 or older and Korean nationals.
                    PSG technicians collected facial photos using the following
                    protocol and equipment. Equipment: Samsung digital camera
                    WB350F. Photography: Facial photos were taken once each
                    from the front and left at 90-degree angles.
                    OSA patients typically have a thick
                    neck and jaw, which is caused by an increase in the amount
                    of muscle and adipose tissue that repetitively obstructs the
                    upper airway. This phenomenon may be related to obesity
                    and may interact with congenital anatomical features of the
                    face, further exacerbating the repetitive obstruction of the
                    upper airway.
                    Unnecessary
                    parts of the images, such as the background, are removed.
                    Using MediaPipe, an open-source face recognition library in
                    Python, we are able to acquire four coordinates (left top, right
                    top, left bottom, right bottom) that enclose the face area.
                    Based on this coordinate information, we crop the original
                    image to obtain only the side face. Additionally, taking
                    into consideration the conditions of the hardware, all images
                    have been resized to (256*256).
                </p>
                <br>
                <img loading="lazy" src="static/images/prepro-pipeline.png" />
            </div>
        </div>
    </section>
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">OSA-Net Architecture</h2>
                <p>The structure of the model we propose is shown in the figure below.</p>
                <img loading='lazy' src='static/images/net-archi.png' style="width: 100%;" />
                <p>
                    OSA-Net is composed of six main stages, with key blocks
                    and layers including the Stem Block, SA Block, global
                    average pooling (GAP), and fully connected layer. CNNs are
                    generally divided into feature extraction and classification
                    areas, and in OSA-Net, Stages 1-5 serve as the feature
                    extraction area while Stage 6 serves as the classification area
                    for determining the class of OSA.
                    SA Block is a core block of our proposed deep
                    learning model based on depthwise-separable convolutional
                    layer. It is composed of 2D-convolutional layer, batch
                    normalization, activation function, depthwise-separable
                    convolutional layer, and SE Block, and is present in OSANet's
                    Stage 2-5 (see Table 1, Stage 2-5). Although all SA
                    Blocks have the same structure, the main parameters of the
                    2D-convolutional layer are different for each one. The filter
                    size of the SA Block's 2D-convolutional layer is (1*1). When
                    the filter size of the convolutional layer is (1*1), the size of
                    the input feature map and the output feature map remains the
                    same, preserving spatial information between them. This is
                    effective in reducing computational complexity and the
                    number of parameters in the model, thus positively impacting
                    the model's training speed and generalization ability.
                </p>
                <br>
                <img loading="lazy" src="static/images/sa-structure.png" alt="human" style="width: 100%; max-width: none;" />
                <!-- <img loading="lazy" src="static/images/controlnet/controlnet_iclr.svg" alt="iclr" /> -->
            </div>
        </div>
    </section>
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">Quantitative comparison with related works</h2>
                <h2>The table below shown the results of a quantitative comparison with previous related works.
                </h2>
                <img loading="lazy" src="static/images/osanet-result-table.png" alt="comp" style="width: 100%; max-width: none;" />
            </div>
        </div>
    </section>
    
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">Model interpretation using Grad-CAM</h2>
                <h2>Grad-CAM is used to interpret the results of a
                    model. Grad-CAM is one of the methodologies for visually
                    interpreting deep learning models.
                </h2>
                <img loading="lazy" src="static/images/osa_cam.png" alt="comp" style="width: 100%; max-width: none;" />
            </div>
        </div>
    </section>


    <!--BibTex citation -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@misc{Lee@koala,
    title={KOALA: Self-Attention Matters in Knowledge Distillation of Latent Diffusion Models for Memory-Efficient and Fast Image Synthesis}, 
    author={Youngwan Lee and Kwanyong Park and Yoorhim Cho and Yong-Ju Lee and Sung Ju Hwang},
    year={2023},
    eprint={2312.04005},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}</code></pre>
        </div>
    </section>
    <!--End BibTex citation -->


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This page was built using the <a
                                href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a
                                href="https://nerfies.github.io" target="_blank">Nerfies</a>Â and Â <a
                                href="https://pixart-alpha.github.io/" target="_blank">PixArt-alpha</a> project pages.
                            You are free to borrow the of this website, we just ask that you link back to this page in
                            the footer. <br> This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p class="has-text-centered">Total clicks: <span id="busuanzi_value_site_pv"></span></p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>