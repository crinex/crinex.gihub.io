<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <!-- <meta name="description" content="DESCRIPTION META TAG"> -->
    <meta property="og:title"
        content="Skip-GANomaly++: Skip Connections and Residual Blocks for Anomaly Detection" />
    <!-- <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" /> -->
    <meta property="og:url" content="https://crinex.github.io/pages/skipganpp/" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <!-- <meta property="og:image" content="static/images/banner.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" /> -->


    <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
    <!-- <meta name="twitter:card" content="summary_large_image"> -->
    <!-- Keywords for your paper to be indexed by-->
    <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE"> -->
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->


    <title>Riemannian Geometric-based Meta Learning</title>
    <!-- <link rel="icon" type="image/x-icon" href="static/images/koala.png">-->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/index.js"></script>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.1.1/gradio.js"></script>
</head>

<body>


    <section class="hero banner">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title"></i>Riemannian Geometric-based Meta Learning<br /></h1>
                            <!-- :Skip Connections and Residual Blocks for Anomaly Detection</h1> -->
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <span class="author-block">
                                <a href="https://aunal.org/people/jypark" target="_blank">†June-Young Park</a><sup style="color:#aa0404;">1</sup><sup style="color:#439b08;">,2</sup>,</span>
                            <span class="author-block">
                                <a href="https://www.dkuh.co.kr/html_2016/03/01_02.php?idx=456150&url=%2Fhtml_2016%2F03%2F01.php&drword=%EC%8B%A0%ED%98%9C%EB%A6%BC" target="_blank">YuMi Lee</a><sup style="color:#ecaa2e;">3</sup>,</span>
                            <span class="author-block">
                                <a href="https://www.dkuh.co.kr/html_2016/03/01_02.php?idx=456150&url=%2Fhtml_2016%2F03%2F01.php&drword=%EC%8B%A0%ED%98%9C%EB%A6%BC" target="_blank">Taejoon Kim</a><sup style="color:#439b08;">2</sup>,</span>
                            <span class="author-block">
                                <a href="https://aunal.org/people/tjkim" target="_blank">Jang-Hwan Choi</a><sup style="color:#ecaa2e;">3</sup></span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup style="color:#aa0404;">1</sup>Opt-AI Inc.,</span>
                            <span class="author-block"><sup style="color:#439b08;">2</sup>Ajou University,</span>
                            <span class="author-block"><sup style="color:#ecaa2e;">3</sup>Ewha Womans University</span>
                            <!-- <span class="author-block"><sup style="color:#ecaa2e;">3</sup>Ajou University School of Medicine</span> -->
                        </div>
                        †{jyoung.park@opt-ai.kr}
                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>AAAI 2025</span>
                    
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="" 
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span> 
                                <span class="link-block">
                                    <a href="" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon" style="vertical-align: middle; font-size: 20px;">&#11088;</span>
                                        <span style="vertical-align: middle;">Torchmeta</span>
                                    </a>
                                </span>  
                                <span class="link-block">
                                    <a href="" 
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fa fa-underline"></i>
                                        </span>
                                        <span>Underline</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="" 
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-code"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>


                                <!-- <span class="link-block">
                                    <a href="https://huggingface.co/docs/diffusers/main/en/api/pipelines/pixart" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">🧨</span>
                                        <span>Diffusers</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://huggingface.co/spaces/PixArt-alpha/PixArt-alpha" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">🤗</span>
                                        <span>HF Demo</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://openxlab.org.cn/apps/detail/PixArt-alpha/PixArt-alpha" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">X</span>
                                        <span>OpenXLab Demo</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2310.00426" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://discord.gg/hWT7caau" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-discord"></i>
                                        </span>
                                        <span>Discord</span>
                                    </a>
                                </span> -->
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Image carousel -->
    <!-- End image carousel -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Meta-learning, or “learning to learn,” aims to enable models
                            to quickly adapt to new tasks with minimal data. While
                            traditional methods like Model-Agnostic Meta-Learning
                            (MAML) optimize parameters in Euclidean space, they often
                            struggle to capture complex learning dynamics, particularly
                            in few-shot learning scenarios. To address this limitation, we
                            propose Stiefel-MAML, which integrates Riemannian geometry
                            by optimizing within the Stiefel manifold, a space that
                            naturally enforces orthogonality constraints. By leveraging
                            the geometric structure of the Stiefel manifold, we improve
                            parameter expressiveness and enable more efficient optimization
                            through Riemannian gradient calculations and retraction
                            operations.We also introduce a novel kernel-based loss function
                            defined on the Stiefel manifold, further enhancing the
                            model's ability to explore the parameter space. Experimental
                            results on benchmark datasets—including Omniglot, Mini-
                            ImageNet, FC-100, and CUB—demonstrate that Stiefel-
                            MAML consistently outperforms traditional MAML, achieving
                            superior performance across various few-shot learning
                            tasks. Our findings highlight the potential of Riemannian geometry
                            to enhance meta-learning, paving the way for future
                            research on optimizing over different geometric structures.
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->
    
    <!-- Start demo page -->
    <!-- <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-centered has-text-centered">
                <h2 class="title is-3">Online Demo</h2>
                <gradio-app src="https://pixart-alpha-pixart-alpha.hf.space" style="display: flex; justify-content: center;"></gradio-app>
            </div>
        </div>
    </section> -->
    <!-- End demo page -->


    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">Proposed Model: SKip-GANomaly++</h2>
                <p>
                   The Skip-GANomaly++ is based on GAN and consists of two subnetworks: a genera-tor and a discriminator. The generator is composed of a single stem block, three encoders, Atrous Spatial Pyrami-dal Pooling (ASPP), and three decoders.
                    Neural network becomes deeper,
                    it can hinder the training process and induce degradation issues. 
                    Thus, we employ residual units (He et al., 2016) in every block. 
                    By using both residual units and skip-connections, we can stabilize the gradients, enabling the training of deeper networks. 
                    Additionally, we employ ASPP at the junction connecting the encoder and decoder. 
                    ASPP, combining atrous convo-lution and spatial pyramid poling, excels at effectively cap-turing varied scales and contextual information from fine to broad regions of the image. 
                    Consequently, ASPP can ef-fectively address the loss of image information that occurs in the Encoder. 
                    The discriminator predicts the class of the given input data. 
                    In GAN, the discriminator differentiates between real images and reconstructed images generated by the generator. 
                    In this model, beyond the aforementioned role, it is also employed to compute the latent representa-tions of both the real and reconstructed images.
                </p>
                <br>
                <img loading="lazy" src="static/images/skipganomalpp2.png" />
            </div>
        </div>
    </section>
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">Experimental Setup</h2>
                <p>
                    To validate the proof of concept for our proposed model, we conduct evaluations using the benchmark CIFAR-10 dataset.
                    Experiments on the CIFAR-10 dataset follow a one-leave-out approach. 
                    The CIFAR-10 dataset comprises 45,000 normal samples for model training and ten distinct test sets, each consisting of 9,000 normal and 6,000 ab-normal samples. 
                    Additionally, for a quantitative evaluation of our model, we conduct comparative experiments with the GANomaly, Skip-GANomaly, AnoGAN (Schlegl et al., 2017) and EGBAD (Zenati et al., 2018) models. All data used for training and testing are resized to 32x32 dimen-sions and normalized, scaling the pixel values between 0 and 1.
                </p>
                <br>
<!--                 <img loading="lazy" src="static/images/sa-structure.png" alt="human" style="width: 100%; max-width: none;" /> -->
                <!-- <img loading="lazy" src="static/images/controlnet/controlnet_iclr.svg" alt="iclr" /> -->
            </div>
        </div>
    </section>
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">Quantitative comparison with related works</h2>
                <h2>The table below shown the results of a quantitative comparison with previous related works.
                </h2>
                <img loading="lazy" src="static/images/skganpp_result_table.png" alt="comp" style="width: 100%; max-width: none;" />
                <p>The model we propose has been benchmarked against models such as GANomaly, Skip-GANomaly, AnoGAN, and EGBAD. Upon examining the results in Table 1, it is evident that, with the exception of the 'car' and 'truck' clas-ses, our model outperforms the established models across all other classes. Notably, classes like 'bird', 'deer', and 'cat' were ones where prior research consistently failed to yield impressive results. However, our proposed model demon-strated superior performance even in these challenging classes. Conseq uently, this paper proposes a model that not only enhances performance compared to existing mod-els but also effectively identifies anomalies.</p>
            </div>
        </div>
    </section>
    
<!--     <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">Model interpretation using Grad-CAM</h2>
                <h2>Grad-CAM is used to interpret the results of a
                    model. Grad-CAM is one of the methodologies for visually
                    interpreting deep learning models.
                </h2>
                <img loading="lazy" src="static/images/osa_cam.png" alt="comp" style="width: 100%; max-width: none;" />
            </div>
        </div>
    </section> -->


    <!--End BibTex citation -->


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This page was built using the <a
                                href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                                href="https://nerfies.github.io" target="_blank">Nerfies</a> and  <a
                                href="https://pixart-alpha.github.io/" target="_blank">PixArt-alpha</a> project pages.
                            You are free to borrow the of this website, we just ask that you link back to this page in
                            the footer. <br> This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p class="has-text-centered">Total clicks: <span id="busuanzi_value_site_pv"></span></p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>
