<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <!-- <meta name="description" content="DESCRIPTION META TAG"> -->
    <meta property="og:title"
        content="OSA-Net: An Efficient Convolutional Neural Network for OSA Diagnosis Screening Tool" />
    <!-- <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" /> -->
    <meta property="og:url" content="https://crinex.github.io/pages/OSA-net/" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <!-- <meta property="og:image" content="static/images/banner.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" /> -->


    <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
    <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
    <!-- <meta name="twitter:card" content="summary_large_image"> -->
    <!-- Keywords for your paper to be indexed by-->
    <!-- <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE"> -->
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->


    <title>OSA-Net</title>
    <!-- <link rel="icon" type="image/x-icon" href="static/images/koala.png">-->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/index.js"></script>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/4.1.1/gradio.js"></script>
</head>

<body>


    <section class="hero banner">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-2 publication-title"></i>OSA-Net<br />
                            :An Efficient Convolutional Neural Network for OSA Diagnosis Screening Tool</h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Paper authors -->
                            <span class="author-block">
                                <a href="https://aunal.org/people/jypark" target="_blank">June-Young Park</a><sup style="color:#aa0404;">1 </sup>,</span>
                            <span class="author-block">
                                <a href="https://www.dkuh.co.kr/html_2016/03/01_02.php?idx=456150&url=%2Fhtml_2016%2F03%2F01.php&drword=%EC%8B%A0%ED%98%9C%EB%A6%BC" target="_blank">Hye-Rim Shin</a><sup style="color:#1b5dd7;">2</sup>,</span>
                            <span class="author-block">
                                <a href="https://aunal.org/people/tjkim" target="_blank">Tae-Joon Kim</a><sup style="color:#ecaa2e;">3</sup></span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup style="color:#aa0404;">1</sup>Graduate School of Medicine Ajou University,</span>
                            <span class="author-block"><sup style="color:#1b5dd7;">2</sup>Dankook University Hospital,</span>
                            <span class="author-block"><sup style="color:#ecaa2e;">3</sup>Ajou University School of Medicine</span>
                        </div>
                        
                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <span class="link-block">
                                    <a href="https://ieeexplore.ieee.org/document/10320072" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>


                                <!-- <span class="link-block">
                                    <a href="https://huggingface.co/docs/diffusers/main/en/api/pipelines/pixart" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">ðŸ§¨</span>
                                        <span>Diffusers</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://huggingface.co/spaces/PixArt-alpha/PixArt-alpha" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">ðŸ¤—</span>
                                        <span>HF Demo</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://openxlab.org.cn/apps/detail/PixArt-alpha/PixArt-alpha" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">X</span>
                                        <span>OpenXLab Demo</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2310.00426" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://discord.gg/hWT7caau" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-discord"></i>
                                        </span>
                                        <span>Discord</span>
                                    </a>
                                </span> -->
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Image carousel -->
    <!-- End image carousel -->

    <!-- Paper abstract -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Obstructive sleep apnea (OSA) has a high prevalence worldwide, particularly among adults and the population with comorbidities. 
                            Adult men have a higher incidence rate and approximately 15-30% prevalence, and OSA is associated with other diseases such as obesity, hypertension, and diabetes. 
                            Polysomnography is essential for diagnosing OSA, but discomfort and overnight testing are practical difficulties. 
                            Therefore, several questionnaires, such as the STOP-BANG and Berlin questionnaire, have been developed for initial screening of OSA, although their use is limited due to their low accuracy. 
                            One of the pathophysiology of OSA is related to craniofacial anatomy, and several previous studies have investigated facial anatomy using 2D or 3D photographs with a small number of patients, 
                            but practical application for screening and diagnosing OSA has not been attempted yet. 
                            Therefore, our research aims to screen OSA and stratify its severity with feasible 2D photographs and a big dataset using a novel deep learning algorithm. 
                            We developed a new CNN-based algorithm called OSA-Net, which diagnoses OSA patients using information on facial anatomical abnormalities by ready-to-use photographs. 
                            Facial pictures of 900 patients who underwent polysomnography were used as a dataset for model training. 
                            The results of our algorithm showed a high diagnostic accuracy over 85% for classifying OSA severity into normal, mild, moderate, and severe degrees. 
                            Furthermore, we used Grad-CAM to verify the accuracy of our model, and the results showed that our model accurately recognizes facial contours. 
                            This study demonstrates the potential of using artificial intelligence with image big data as a new OSA screening tool.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- End paper abstract -->
    
    <!-- Start demo page -->
    <!-- <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-centered has-text-centered">
                <h2 class="title is-3">Online Demo</h2>
                <gradio-app src="https://pixart-alpha-pixart-alpha.hf.space" style="display: flex; justify-content: center;"></gradio-app>
            </div>
        </div>
    </section> -->
    <!-- End demo page -->


    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">Datasets & Preprocessing</h2>
                <p>
                    To train and evaluate our proposed OSA-Net model,
                    we used facial images of patients who underwent PSG tests
                    at the Neurology Department of Cheonan Dankook
                    University Hospital from 2012 to 2022. 
                    The data were obtained from adults aged 19 or older and Korean nationals.
                    PSG technicians collected facial photos using the following
                    protocol and equipment. Equipment: Samsung digital camera
                    WB350F. Photography: Facial photos were taken once each
                    from the front and left at 90-degree angles.
                    OSA patients typically have a thick
                    neck and jaw, which is caused by an increase in the amount
                    of muscle and adipose tissue that repetitively obstructs the
                    upper airway. This phenomenon may be related to obesity
                    and may interact with congenital anatomical features of the
                    face, further exacerbating the repetitive obstruction of the
                    upper airway.
                    Unnecessary
                    parts of the images, such as the background, are removed.
                    Using MediaPipe, an open-source face recognition library in
                    Python, we are able to acquire four coordinates (left top, right
                    top, left bottom, right bottom) that enclose the face area.
                    Based on this coordinate information, we crop the original
                    image to obtain only the side face [17]. Additionally, taking
                    into consideration the conditions of the hardware, all images
                    have been resized to (256*256).
                </p>
                <br>
                <img loading="lazy" src="static/images/prepro-pipeline.png" />
            </div>
        </div>
    </section>
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">Qualitative comparison</h2>
                <p>We follow the official inference setups of each model (<a
                    href="https://huggingface.co/stabilityai/stable-diffusion-2"
                    target="_blank">SDM-v2.0</a> and <a
                    href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0"
                    target="_blank">SDXL-Base-1.0</a>) in the huggingface repository. 
                    Specifically, SDM-v2.0 is set to generate with DDIM scheduler with 25 steps and SDXL and ours are set to use Euler discrete scheduler with 25 steps. 
                    And we set all models to use the classifier-free guidance with 7.5.
                    Except DALLE-2, we generate all images with FP16 precision.
                For DALLE-2, we get generated images via OpenAI API.
                <br>
                </p>
                <img loading="lazy" src="static/images/sota_human_updated.svg" alt="human" style="width: 100%; max-width: none;" />
                <img loading="lazy" src="static/images/sota_3d-art_updated.svg" alt="3d" style="width: 100%; max-width: none;" />
                <img loading="lazy" src="static/images/sota_painting_updated.svg" alt="painting" style="width: 100%; max-width: none;" />
                <!-- <img loading="lazy" src="static/images/controlnet/controlnet_iclr.svg" alt="iclr" /> -->
            </div>
        </div>
    </section>
    <section class="hero is-small">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <h2 class="title is-3">Qualitative comparison with SDM-v2.0 and SDXL-Base-1.0</h2>
                <h2>For each prompt, we use 4 random seeds to generate images, while all models are generated with the same seed for each image.
                </h2>
                <img loading="lazy" src="static/images/sota_comparison_updated.svg" alt="comp" style="width: 100%; max-width: none;" />
            </div>
        </div>
    </section>


    <!--BibTex citation -->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@misc{Lee@koala,
    title={KOALA: Self-Attention Matters in Knowledge Distillation of Latent Diffusion Models for Memory-Efficient and Fast Image Synthesis}, 
    author={Youngwan Lee and Kwanyong Park and Yoorhim Cho and Yong-Ju Lee and Sung Ju Hwang},
    year={2023},
    eprint={2312.04005},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}</code></pre>
        </div>
    </section>
    <!--End BibTex citation -->


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This page was built using the <a
                                href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a
                                href="https://nerfies.github.io" target="_blank">Nerfies</a>Â and Â <a
                                href="https://pixart-alpha.github.io/" target="_blank">PixArt-alpha</a> project pages.
                            You are free to borrow the of this website, we just ask that you link back to this page in
                            the footer. <br> This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p class="has-text-centered">Total clicks: <span id="busuanzi_value_site_pv"></span></p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Statcounter tracking code -->

    <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

</body>

</html>
